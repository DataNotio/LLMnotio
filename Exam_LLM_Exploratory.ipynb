{"cells":[{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["#!pip install langchain_openai\n","#!pip install chromadb\n","#!pip install transformers\n","#!pip install faiss-cpu\n","#!pip install -qU langchain-huggingface\n","#!pip install -U langchain-community\n","#!pip install langchain"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["import bs4\n","from langchain import hub\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_community.vectorstores import Chroma\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","\n","loader = WebBaseLoader(\n","    web_paths=(\"https://other-docs.snowflake.com/en/polaris/overview\",),\n",")\n","docs = loader.load()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["data = []\n","for doc in docs:\n","  page_number = doc.metadata['source']\n","  page_title = doc.metadata['title']\n","  page_content = doc.page_content\n","  data.append([page_number,page_title, page_content])\n","\n","df = pd.DataFrame(data, columns=['Page','Page Title','Content'])"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 40 English links. Loading documents...\n","                                                Page  \\\n","0  https://docs.snowflake.com/en/user-guide/data-...   \n","1  https://docs.snowflake.com/en/user-guide/dynam...   \n","2  https://docs.snowflake.com/en/release-notes/ne...   \n","3  https://docs.snowflake.com/en/user-guide-getti...   \n","4            https://docs.snowflake.com/en/reference   \n","\n","                                          Page Title  \\\n","0  Understanding & using Time Travel | Snowflake ...   \n","1           Dynamic tables | Snowflake Documentation   \n","2               What’s New | Snowflake Documentation   \n","3          Getting Started - Snowflake Documentation   \n","4                Reference | Snowflake Documentation   \n","\n","                                             Content  \n","0  Understanding & using Time Travel | Snowflake ...  \n","1  Dynamic tables | Snowflake DocumentationDOCUME...  \n","2  What’s New | Snowflake DocumentationDOCUMENTAT...  \n","3  Getting Started - Snowflake DocumentationDOCUM...  \n","4  Reference | Snowflake DocumentationDOCUMENTATI...  \n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def get_english_links(url):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","        links = soup.find_all('a')\n","        hrefs = {link.get('href') for link in links if link.get('href')}\n","        english_links = {href for href in hrefs if '/en/' in href}\n","        english_links = {href if href.startswith('http') else url + href for href in english_links}\n","        return english_links\n","    else:\n","        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n","        return set()\n","\n","def load_documents_from_links(links):\n","    loader = WebBaseLoader(web_paths=tuple(links))\n","    docs = loader.load()\n","    data = []\n","    for doc in docs:\n","        page_number = doc.metadata['source']\n","        page_title = doc.metadata['title']\n","        page_content = doc.page_content\n","        data.append([page_number, page_title, page_content])\n","    return pd.DataFrame(data, columns=['Page', 'Page Title', 'Content']), docs\n","\n","\n","url = \"https://docs.snowflake.com\"\n","english_links = get_english_links(url)\n","if english_links:\n","    print(f\"Found {len(english_links)} English links. Loading documents...\")\n","    df, docs = load_documents_from_links(english_links)\n","    print(df.head())\n","else:\n","    print(\"No English links found or webpage could not be accessed.\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/python/3.10.13/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["import faiss\n","from langchain_community.vectorstores import FAISS\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain import hub\n","from uuid import uuid4\n","\n","embeddings = HuggingFaceEmbeddings()\n","vectorstore = FAISS.from_documents(docs, embeddings)\n","retriever = vectorstore.as_retriever()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["documents = vectorstore.similarity_search('What is a warehouse?')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Virtual warehouses | Snowflake DocumentationDOCUMENTATION/Getting StartedGuidesDeveloperReferenceReleasesTutorialsPolaris CatalogStatusOverviewSnowflake HorizonConnecting to SnowflakeVirtual warehousesOverviewMulticlusterConsiderationsWorking with warehousesQuery Acceleration ServiceMonitoring loadSnowpark-optimized warehousesDatabases, Tables, & ViewsData TypesData LoadingData UnloadingQueriesData Sharing and CollaborationSnowflake AI & MLAlerts & NotificationsSecurityData GovernancePrivacyOrganizations & AccountsBusiness Continuity & Data RecoveryPerformance OptimizationCost & BillingGuidesVirtual warehouses\n","\n","Virtual warehouses¶\n","A virtual warehouse, often referred to simply as a “warehouse”, is a cluster of compute resources in Snowflake. A virtual warehouse is\n","available in two types:\n","\n","Standard\n","Snowpark-optimized\n","\n","A warehouse provides the required resources, such as CPU, memory, and temporary storage, to\n","perform the following operations in a Snowflake session:\n","\n","Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).\n","Performing DML operations, such as:\n","\n","Updating rows in tables (DELETE , INSERT , UPDATE).\n","Loading data into tables (COPY INTO <table>).\n","Unloading data from tables  (COPY INTO <location>).\n","\n","\n","\n","\n","Note\n","To perform these operations, a warehouse must be running and in use for the session. While a warehouse is running, it consumes Snowflake\n","credits.\n","\n","\n","Overview of warehousesWarehouses are required for queries, as well as all DML operations, including loading data into tables.\n","In addition to being defined by its type as either Standard or Snowpark-optimized, a warehouse is defined by its size,\n","as well as the other properties that can be set to help control and automate warehouse activity.\n","\n","Snowpark-optimized warehousesSnowpark workloads can be run on both Standard and Snowpark-optimized warehouses. Snowpark-optimized warehouses are recommended for workloads that have large memory requirements such as ML training use cases\n","\n","Warehouse considerationsBest practices and general guidelines for using virtual warehouses in Snowflake to process queries\n","\n","Multi-cluster warehousesMulti-cluster warehouses enable you to scale compute resources to manage your user and query concurrency needs as they change, such as during peak and off hours.\n","\n","Working with warehousesLearn how to create, stop, start and otherwise manage Snowflake warehouses.\n","\n","Using the Query Acceleration ServiceThe query acceleration service can accelerate parts of the query workload in a warehouse.\n","When enabled for a warehouse, query acceleration can improve overall warehouse performance by reducing the impact of outlier queries\n","(i.e. queries which use more resources then typical queries).\n","\n","Monitoring warehouse loadWarehouse query load measures the average number of queries that were running or queued within a specific interval.\n","\n","\n","\n","\n","Overview of warehouses\n","Snowpark-optimized warehouses\n","Warehouse considerations\n","Multi-cluster warehouses\n","Working with warehouses\n","Using the Query Acceleration Service\n","Monitoring warehouse load\n","\n","\n","\n","Was this page helpful?YesNoVisit SnowflakeJoin the conversationDevelop with SnowflakeShare your feedbackRead the latest on our blogGet your own certificationPrivacy NoticeSite Terms© 2024 Snowflake, Inc. All Rights Reserved.Related contentUnderstanding compute costWorking with resource monitorsLanguage: EnglishEnglishFrançaisDeutsch日本語한국어Português\n","------------------------------------------------------------------------------------------------------------------------------------\n","Guides - Snowflake DocumentationDOCUMENTATION/Getting StartedGuidesDeveloperReferenceReleasesTutorialsPolaris CatalogStatusOverviewSnowflake HorizonConnecting to SnowflakeVirtual warehousesDatabases, Tables, & ViewsData TypesData LoadingData UnloadingQueriesData Sharing and CollaborationSnowflake AI & MLAlerts & NotificationsSecurityData GovernancePrivacyOrganizations & AccountsBusiness Continuity & Data RecoveryPerformance OptimizationCost & BillingUser GuidesInstructions on performing various Snowflake operationsConnecting to SnowflakeSnowflake provides a variety of mechanisms for connecting to Snowflake and executing database commands. Choose between the web interface or the command line tool to connect to your Snowflake account. Learn how to use connectors to integrate third-party data into Snowflake.See allWeb InterfaceSnowsight distills Snowflake’s powerful SQL support into a unified, easy-to-use experience. Use Snowsight to perform your critical Snowflake operations.Learn moreCommand LineDetailed instructions for installing, configuring, and using the Snowflake command-line client, snowsql.Learn moreConnectorsThe Snowflake Connectors provide native integration of third-party applications and database systems in Snowflake. The connectors provide instant access to current data without the need to manually integrate against API endpoints.Learn moreSnowflake FundamentalsLearn the basics of warehouses, tables, and views in Snowflake.Snowflake WarehousesLearn how to set up and use virtual data warehouses to process the SQL statements that you execute.Overview of WarehousesMulti-cluster WarehousesWarehouse ConsiderationsWorking with WarehousesUsing the Query Acceleration ServiceSee allBasics of Snowflake Tables and ViewsLearn how to design and create tables and views for your data.Understanding Snowflake Table StructuresTable Design ConsiderationsOverview of ViewsWorking with Secure ViewsCloning ConsiderationsTable Storage ConsiderationsSee allBasics of Data TypesLearn about Snowflake data types and their usesIntroduction to Snowflake Data TypesNumeric Data TypesString and Binary Data TypesLogical Data TypesDate & Time Data TypesGeospatial Data TypesSee allGetting data in to SnowflakeSnowflake provides several different methods to load data in to Snowflake, such as by using Snowpipe, loading from cloud storage, or uploading files using Snowsight.Understanding Data LoadingData can be loaded into Snowflake in a number of ways. Learn about data loading concepts, different tasks, tools, and techniques to quickly and easily load data into Snowflake.Bulk Data LoadingLearn to use the COPY command to load data on-demand directly from an AWS S3 bucket, Google Cloud Share, or a Microsoft Azure storage container into Snowflake.SnowpipeUse Snowflake Snowpipe to load data automatically as it arrives.Working with dataQueries and other standard database features are just the beginning when you work with your data in Snowflake. You also use machine learning functions to analyze data in Snowflake.See allQueriesSnowflake supports standard SQL, including a subset of ANSI SQL:1999 and the SQL:2003 analytic extensions. Learn how to use queries to interact with Snowflake using simple queries, joins, and more.Learn moreViews, Materialized Views, & Dynamic TablesViews are just the beginning of how you can examine data. Snowflake provides a number of mechanism for joining data including Materialized Views and Dynamic Tables.Learn moreStreams and TasksStreams and tasks make executing complex task based solutions simple and easy. Streams allow you to track changes to database objects and tasks provide a mechanism to then execute SQL when those events occur.Learn moreML FunctionsML Functions are Snowflake’s intelligent, fully-managed service that enables organizations to quickly analyze data within Snowflake.Learn moreCollaboratingShare data and applications with other Snowflake users. Discover and publish listings of data products on the Snowflake Marketplace, share data products privately, or use a direct share to quickly share data with someone in the same region.What are listings?With listings, you can provide data and other information to other Snowflake users, and you can access data and other information shared by Snowflake providers.Becoming a listing providerBecoming a provider of listings in Snowflake makes it easier to manage sharing from your account to other Snowflake accounts.Becoming a listing consumerGet access to data products shared privately or on the Snowflake Marketplace by becoming a consumer of listings.More GuidesAlerts and NotificationsSetting Up Alerts Based on Data in SnowflakeSending Email NotificationsSee allSecurityAuthenticationAccess ControlEncryption key managementEncryptionNetworkingSee allGovernance and ComplianceData Lineage and DependenciesData Access PoliciesData SensitivityClassificationComplianceSee allPrivacyAggregation PoliciesProjection PoliciesSee allOrganizations and AccountsOrganizationsAccount identifiersSee allBusiness Continuity & Data RecoveryReplication & FailoverClient RedirectTime TravelFail-safeSee allPerformance and CostCost ManagementQuery PerformanceSee allWas this page helpful?YesNoVisit SnowflakeJoin the conversationDevelop with SnowflakeShare your feedbackRead the latest on our blogGet your own certificationPrivacy NoticeSite Terms© 2024 Snowflake, Inc. All Rights Reserved.Language: EnglishEnglishFrançaisDeutsch日本語한국어Português\n","------------------------------------------------------------------------------------------------------------------------------------\n","Bulk loading from a local file system | Snowflake DocumentationDOCUMENTATION/Getting StartedGuidesDeveloperReferenceReleasesTutorialsPolaris CatalogStatusOverviewSnowflake HorizonConnecting to SnowflakeVirtual warehousesDatabases, Tables, & ViewsData TypesData LoadingOverviewFeature SummaryConsiderationsPreparing to Load DataStaging Files Using SnowsightLoading Data Using the Web InterfaceMonitor data loading activityBulk LoadingLocal File SystemChoosing an Internal StageStaging FilesCopying Data from a Local File SystemAmazon S3Google Cloud StorageMicrosoft AzureTroubleshootingSnowpipeOverviewAuto IngestREST EndpointsError NotificationsTroubleshootingManagingSnowpipe CostsSnowpipe StreamingOverviewConfigurations and ExamplesRecommendationsSnowpipe Streaming CostsKafka Connector with Snowpipe StreamingSchema Detection and Evolution for Kafka Connector with Snowpipe StreamingLoading Semi-Structured DataIntroductionSupported FormatsConsiderationsAccessing Unstructured DataIntroductionDirectory TablesREST APIProcessing with UDF and Procedure HandlersSharingTroubleshootingAccessing Data in Other StorageAmazon S3-compatible StorageQuerying and Transforming DataQuerying Data in Staged FilesQuerying Metadata for Staged FilesTransforming Data During LoadEvolving Table Schema AutomaticallyContinuous Data PipelinesOverviewDynamic tablesStreamsTasksExamplesData UnloadingQueriesData Sharing and CollaborationSnowflake AI & MLAlerts & NotificationsSecurityData GovernancePrivacyOrganizations & AccountsBusiness Continuity & Data RecoveryPerformance OptimizationCost & BillingGuidesData LoadingLocal File System\n","\n","Bulk loading from a local file system¶\n","This set of topics describes how to use the COPY command to bulk load data from a local file system into tables using an internal (i.e.\n","Snowflake-managed) stage. For instructions on loading data from a cloud storage location that you manage, refer to Bulk loading from Amazon S3, Bulk loading from Google Cloud Storage, or Bulk loading from Microsoft Azure.\n","As illustrated in the diagram below, loading data from a local file system is performed in two, separate steps:\n","\n","Step 1:\n","Upload (i.e. stage) one or more data files to a Snowflake stage (named internal stage or table/user stage) using the PUT command.\n","\n","Step 2:\n","Use the COPY INTO <table> command to load the contents of the staged file(s) into a Snowflake database table.\n","Regardless of the stage you use, this step requires a running virtual warehouse that is also the current (i.e. in use) warehouse for the session. The warehouse provides the compute resources to\n","perform the actual insertion of rows into the table.\n","\n","\n","\n","\n","\n","\n","Tip\n","The instructions in this set of topics assume you have read Preparing to load data and have created a named file format, if desired.\n","Before you begin, you may also want to read Data loading considerations for best practices, tips, and other guidance.\n","\n","Next Topics:\n","\n","Configuration tasks (complete as needed):\n","\n","\n","Choosing an internal stage for local files\n","\n","\n","\n","Data loading tasks (complete for each set of files you load):\n","\n","\n","Staging data files from a local file system\n","Copying data from an internal stage\n","\n","\n","\n","\n","\n","Was this page helpful?YesNoVisit SnowflakeJoin the conversationDevelop with SnowflakeShare your feedbackRead the latest on our blogGet your own certificationPrivacy NoticeSite Terms© 2024 Snowflake, Inc. All Rights Reserved.Related contentUnloading into a Snowflake stageLanguage: EnglishEnglishFrançaisDeutsch日本語한국어Português\n","------------------------------------------------------------------------------------------------------------------------------------\n","Snowflake DocumentationDOCUMENTATION/Getting StartedGuidesDeveloperReferenceReleasesTutorialsPolaris CatalogStatusSnowflake DocumentationStreamline your Snowflake journey with comprehensive documentation and learning resourcesFeatured ResourcesDive into our top picksuser guideConnecting to SnowflakeLearn about the applications and tools that you can use to access Snowflakeuser guideWorking with Virtual WarehousesLearn how to create and manage warehouses, which are used to process queriesuser guideDatabases, Tables and ViewsLearn how to create and manage databases, tables, and views for storing and accessing your datauser guideLoad Data into SnowflakeLearn about the different options for getting data into Snowflake and setting up a pipeline to transform your dataDiscover the Most Popular ResourcesGetting StartedBasic information and instructions for first-time users of Snowflake.Getting a Trial AccountSnowflake in 20 MinutesKey Concepts and ArchitectureConnecting to SnowflakeSee allUser GuidesInstructions on performing various Snowflake operations.Understanding & Using Time TravelWorking with Temporary and Transient TablesWorking with Materialized ViewsSee allDeveloper GuidesWrite applications that extend Snowflake, act as a client, or act as an integrating component.Snowflake Native App FrameworkSnowpark APIUser-defined Functions (UDFs) and Stored ProceduresDriversSee allReferenceReference for SQL data types, SQL commands, SQL functions, SQL classes, scripting, views, and other areasSQL Data TypesSQL CommandsSQL FunctionsSQL ClassesSnowflake ScriptingSee allTutorialsTutorials to help you learn the basics of using SnowflakeSnowflake in 20 MinutesBulk Loading from a Local File SystemBulk Loading from Amazon S3 Using COPYSee allReleasesOverview of the new features, enhancements, and important fixes introduced in the most recent releases of Snowflake.New featuresBehavior change logSnowflake connector, driver, and library monthly releasesSee allWhat’s NewOverview of the new features, enhancements, and important behavior changes introduced in the most recent releases of SnowflakeSee allRecent Product Updatesgenerally availableOn April 29, 2024Dynamic TablesWith this release, we are pleased to announce the general availability of dynamic tables, a new table type for continuous processing pipelines.generally availableOn April 11th, 2024BudgetsWith this release, we are pleased to announce the general availability of Budgets which enables account-level monitoring and notification of Snowflake credit usage for a group of specific Snowflake objects.generally availableOn April 23, 2024Snowflake Connector for ServiceNow® V2generally availableOn May 13, 2024ASOF JOINpreviewOn May 09, 2024Python user-defined aggregate functionspreviewOn May 03, 2024Snowflake Model RegistryAnnouncementsStay informed and discover the latest updates, improvements, and enhancementsBehavior ChangesBehavior changes that may impact your usageDeprecated FeaturesFeatures and operating systems/programming languages that are deprecated or pending deprecationPerformance ImprovementsAll features that can improve performance and make queries run fasterVisit SnowflakeJoin the conversationDevelop with SnowflakeShare your feedbackRead the latest on our blogGet your own certificationPrivacy NoticeSite Terms© 2024 Snowflake, Inc. All Rights Reserved.Language: EnglishEnglishFrançaisDeutsch日本語한국어Português\n","------------------------------------------------------------------------------------------------------------------------------------\n"]}],"source":["for docs in documents:\n","    print(docs.page_content)\n","    print('------------------------------------------------------------------------------------------------------------------------------------')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
